Name,Paper,Dataset,Model,Method,Notes,NumTrials,Err1,Err5,Top1,stdTop1,dTop1,Top5,dTop5,MParams,savedParams,keptParams,GFLOPS,savedFLOPS,keptFLOPS,OrigTop1,stdOrigTop1,OrigTop5,OrigMParams,OrigGFLOPS,old/new Nparam,old/new FLOPS,OrigErr1,OrigErr5
326,amc-automl-han,CIFAR-10,Plain-20,,,,,,,,,,,,,,,,,,,,,,,,,
328,amc-automl-han,CIFAR-10,ResNet-50,,"usage of ""compression ratio"": "" The result we obtain has up to 60% compression ratio with even a little higher accuracy on both validation set and test set"" But it does suggest that higher is better, so their ""60%"" under ""Ratio"" column in Table 2 is fraction saved",,,,93.55%,,,,,,60.00%,,,,,93.53%,,,,,,,,
327,amc-automl-han,CIFAR-10,ResNet-56,,,,,,91.90%,,,,,,,,,50.00%,,92.80%,,,,,,,,
330,amc-automl-han,ImageNet,MobileNet,,table3,,,,,,-0.400%,,,,50.00%,,,,,70.60%,,,,,,,,
431,amc-automl-han,ImageNet,MobileNet,,table3,,,,,,-1.700%,,,,60.00%,,,,,70.60%,,,,,,,,
432,amc-automl-han,ImageNet,MobileNet,,table4,,,,70.50%,,,89.30%,,,50.00%,,,,,70.60%,,,,,,,,
331,amc-automl-han,ImageNet,MobileNet-v2,,table3,,,,,,-1.000%,,,,50.00%,,,,,71.80%,,,,,,,,
329,amc-automl-han,ImageNet,VGG-16,,table3,,,,,,-1.400%,,,,80.00%,,,,,70.50%,,,,,,,,
90,apple-pfa,CIFAR-10,ResNet-56,PFA-En,"10 trials for all their results, but no stds/err bars",10,,,,,-0.180%,,,,,61.50%,,,69.90%,,,,,,,,,
488,apple-pfa,CIFAR-10,ResNet-56,PFA-KL,,10,,,,,-0.610%,,,,,59.60%,,,61.50%,,,,,,,,,
91,apple-pfa,CIFAR-10,SimpleCNN,,,10,,,,,,,,,,,,,,,,,,,,,,
89,apple-pfa,CIFAR-10,VGG-Torch-CIFAR10,PFA-En,,10,,,,,0.400%,,,,,12.70%,,,39.10%,,,,,,,,,
487,apple-pfa,CIFAR-10,VGG-Torch-CIFAR10,PFA-KL,,10,,,,,0.240%,,,,,19.60%,,,39.40%,,,,,,,,,
93,apple-pfa,CIFAR-100,ResNet-56,PFA-En,,10,,,,,-1.680%,,,,,81.50%,,,79.40%,,,,,,,,,
490,apple-pfa,CIFAR-100,ResNet-56,PFA-KL,,10,,,,,-2.850%,,,,,73.60%,,,66.70%,,,,,,,,,
94,apple-pfa,CIFAR-100,SimpleCNN,,,10,,,,,,,,,,,,,,,,,,,,,,
92,apple-pfa,CIFAR-100,VGG-Torch-CIFAR10,PFA-En,,10,,,,,1.400%,,,,,33.10%,,,57.10%,,,,,,,,,
489,apple-pfa,CIFAR-100,VGG-Torch-CIFAR10,PFA-KL,,10,,,,,1.400%,,,,,41.90%,,,53.90%,,,,,,,,,
52,autopruner,CUB200-2011,VGG-16,,"VGG16 was only ""fine-tuned"" on this dataset, so presumably pretained on imagenet",3,,,,,,,,,,,,,,,,,,,,,,
54,autopruner,ImageNet,ResNet-50,,,,,,73.04%,,,91.25%,,,,,2.6400,,,76.15%,,92.87%,,7.729,,,,
373,autopruner,ImageNet,ResNet-50,,,,,,74.76%,,,92.15%,,,,,3.7600,,,76.15%,,92.87%,,7.729,,,,
53,autopruner,ImageNet,VGG-16,,,,,,69.20%,,,88.89%,,,,,8.1700,,,71.59%,,90.38%,,30.949,,,,
298,babu-data-free-pruning,ImageNet,CaffeNet,,"""we use an AlexNet-like architecture, called CaffeNet""; using rows table2 that contain blue, which are seemingly the ones that use their method",,,,48.16%,,,,,,61.17%,,,,,57.84%,,,60.900,,,,,
427,babu-data-free-pruning,ImageNet,CaffeNet,,"""we use an AlexNet-like architecture, called CaffeNet""; using rows table2 that contain blue, which are seemingly the ones that use their method",,,,44.56%,,,,,,47.88%,,,,,57.84%,,,60.900,,,,,
428,babu-data-free-pruning,ImageNet,CaffeNet,,"""we use an AlexNet-like architecture, called CaffeNet""; using rows table2 that contain blue, which are seemingly the ones that use their method",,,,49.76%,,,,,,23.50%,,,,,57.84%,,,60.900,,,,,
312,babu-data-free-pruning,MNIST,LeNet-5-Caffe,,"""The network consisted of a two 5x5 convolutional layers with 20 and 50 filters, and two fully connected layers with 500 and 10 (output layer) neurons.""",,,,,,,,,,,,,,,,,,,,,,,
320,babu-generalized-dropout,CIFAR-10,GenericNet,,no size / speed changes mentioned; only acc,,,,,,,,,,,,,,,,,,,,,,,
317,babu-generalized-dropout,CIFAR-10,ResNet-32,,no size / speed changes mentioned; only acc,,,,,,,,,,,,,,,,,,,,,,,
319,babu-generalized-dropout,CIFAR-10,ResNet-56,,no size / speed changes mentioned; only acc,,,,,,,,,,,,,,,,,,,,,,,
318,babu-generalized-dropout,MNIST,LeNet-5-Caffe,,"they don't use its name; they just say ""we use the standard LeNet-like architecture [16], which consists of two 5 x 5 convolutional layers with 20 and 50 filters, and two fully connected layers with 500 and 10 (output layer) neurons.""",,,,,,,,,,,,,,,,,,,,,,,
322,babu-learning-architecture,ImageNet,CaffeNet,,explicitly say caffenet,,,,55.90%,,,,,19.6000,67.80%,,,,,57.41%,,,60.900,,,,,
429,babu-learning-architecture,ImageNet,CaffeNet,,explicitly say caffenet,,,,54.30%,,,,,19.8000,67.40%,,,,,57.41%,,,60.900,,,,,
430,babu-learning-architecture,ImageNet,CaffeNet,,explicitly say caffenet,,,,55.87%,,,,,47.8000,22.00%,,,,,57.41%,,,60.900,,,,,
321,babu-learning-architecture,MNIST,LeNet-5-Caffe,,"again, don't say its name explicitly; just ""The network consists of two 5 × 5 convolutional layers with 20 and 50 filters, and two fully connected layers with 500 and 10 (output layer) neurons.""",,,,,,,,,,,,,,,,,,,,,,,
324,babu-training-sparse,ImageNet,AlexNet,,,,,,56.96%,,,,,5.9000,,,,,,57.20%,,,60.900,,10.30,,,
325,babu-training-sparse,ImageNet,VGG-16,,,,,,69.04%,,,,,9.8500,,,,,,68.97%,,,138.000,,14.00,,,
323,babu-training-sparse,MNIST,LeNet-5,,,,,,,,,,,,,,,,,,,,,,,,,
69,balanced-sparsity,ImageNet,VGG-16,,"confusing: ""The time cost of other layers in VGG-16, such as pooling and batch normalization, is about 230us"". But there's no batchnorm in vgg-16.... Unrelated: acc number is from ""All these three methods as well as the dense model baseline achieve similar top-5 accuracy of 90.3%, however, under different sparsity ratios."" stated in text, not table",,,,,,,90.30%,,,92.00%,,,,,,,,,,,,,
70,balanced-sparsity,PTB,LSTM-1500-1500,,,,,,,,,,,,,,,,,,,,,,,,,
71,balanced-sparsity,TIMIT,Bi-LSTM-1024,,call this a CTC model (graves et al 2006),,,,,,,,,,,,,,,,,,,,,,,
124,bayesian-compression,CIFAR-10,VGG-Torch-CIFAR10,,,,,,,,,,,,,,,,,,,,,,,,,
123,bayesian-compression,MNIST,LeNet-5-Caffe,,explicitly say they use lenet-5-caffe,,,,,,,,,,,,,,,,,,,,,,,
122,bayesian-compression,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
126,block-sparse-rnns,(Proprietary),GRU Dense 2560,,,,,,,,,,,,,,,,,,,,,,,,,
125,block-sparse-rnns,(Proprietary),RNN Dense 1760,,,,,,,,,,,,,,,,,,,,,,,,,
130,channel-lasso-lstsq,CIFAR-10,ResNet-50,,,,,,,,,,,,,,,,,,,,,,,,,
132,channel-lasso-lstsq,CIFAR-10,Resnet-50-DWSep,,,,,,,,,,,,,,,,,,,,,,,,,
127,channel-lasso-lstsq,CIFAR-10,ResNet-56,,"""Shown in Table 8, our approach is competitive with scratch trained one, without fine-tuning, under 2× speed-up.""",,,,,,-1.000%,,,,,,,,,92.80%,,,,,,2.000,,
131,channel-lasso-lstsq,ImageNet,ResNet-50,,,,,,,,,,-1.400%,,,,,50.00%,,,,92.20%,,,,,,
133,channel-lasso-lstsq,ImageNet,Resnet-50-DWSep,,,,,,,,,,,,,,,,,,,,,,,,,
128,channel-lasso-lstsq,ImageNet,VGG-16,,table 1,,,,,,,,0.000%,,,,,50.00%,,,,89.90%,,,,,,
393,channel-lasso-lstsq,ImageNet,VGG-16,,table 1,,,,,,,,-1.000%,,,,,75.00%,,,,89.90%,,,,,,
394,channel-lasso-lstsq,ImageNet,VGG-16,,table 1,,,,,,,,-1.700%,,,,,80.00%,,,,89.90%,,,,,,
395,channel-lasso-lstsq,ImageNet,VGG-16,3C,"table 2 (""Our 3C (fine-tuned)"")",,,,,,,,0.000%,,,,,75.00%,,,,89.90%,,,,,,
396,channel-lasso-lstsq,ImageNet,VGG-16,3C,"table 2 (""Our 3C (fine-tuned)"")",,,,,,,,0.300%,,,,,80.00%,,,,89.90%,,,,,,
129,channel-lasso-lstsq,Pascal VOC 2007,VGG-16,,using Faster R-CNN,,,,,,,,,,,,,,,,,89.90%,,,,,,
547,compression-aware-training,ICDAR,Dec-3-512,,,,,,,,,,,,,,,,,,,,,,,,,
554,compression-aware-training,ICDAR,Dec-8-256,,,,,,,,,,,,,,,,,,,,,,,,,
555,compression-aware-training,ICDAR,ResNet-50,,"haven't defined ""compression rate""; really unsure what they mean by this based on text in Sec5",,,,75.20%,,,,,,27.00%,,,,,74.70%,,,18.000,,,,,
614,compression-aware-training,ImageNet,Dec-8-512,,,,,,,,,,,,,,,,,,,,,,,,,
612,compression-aware-training,ImageNet,ResNet-50,,"haven't defined ""compression rate""; really unsure what they mean by this based on text in Sec5",,,,75.00%,,,,,,20.60%,,,,,74.70%,,,18.000,,,,,
166,course-pruning,CIFAR-10,CNN_large,,,,,,,,,,,,,,,,,,,,,,,,,
165,course-pruning,CIFAR-10,CNN_small,,,,,,,,,,,,,,,,,,,,,,,,,
159,course-pruning,SVHN,CNN_medium,,,,,,,,,,,,,,,,,,,,,,,,,
599,crossbar-aware,CIFAR-10,VGG8,,"you can't figure out acc drop from what they report, but it's no more than 4% (they give this percentage as stopping condition)",,,,,,,,,,,,,,,,,,,,,,,
598,crossbar-aware,ImageNet,ResNet-18,,"you can't figure out acc drop from what they report, but it's no more than 3.5% (they give this percentage as stopping condition)",,,,,,,,,,,,,,,,,,,,,,,
596,crossbar-aware,ImageNet,VGG-16,,"you can't figure out acc drop from what they report, but it's no more than 4% (they give this percentage as stopping condition)",,,,,,,,,,,,,,,,,,,,,,,
316,dai-info-bottleneck,CIFAR-10,VGG-16-fc512,,same issue as other cifar-10 model,,,,,,,,,,,,,,,,,,,,,,,
308,dai-info-bottleneck,CIFAR-10,VGG-16-fc512-512,,"contradictions in literature? They say they do the same thing as bayesian-compression, but also say ""For the BC models, the dimension of the fully connected layers is simply changed from 4096 to 512, while leaving convolutional layers unaltered""; but bayesian-compression paper definitely says they use the torch-cifar10 vgg, which also has BatchNorm and dropout",,,,,,,,,,,,,,,,,,,,,,,
315,dai-info-bottleneck,CIFAR-10,VGG-netslim,,,,,,,,,,,,,,,,,,,,,,,,,
309,dai-info-bottleneck,CIFAR-100,VGG-Torch-CIFAR10,,"two variations, apparently matching the settings of network-slimming (called NS) and runtime pruning (called RNP)",,,,,,,,,,,,,,,,,,,,,,,
297,dai-info-bottleneck,MNIST,LeNet-5-Caffe,,,,,,,,,,,,,,,,,,,,,,,,,
296,dai-info-bottleneck,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
558,ding-auto-balanced,CIFAR-10,ResNet-56,,"table 3, AFP-G",,7.06%,,,,,,,,,,0.0555,,,,,,,0.142,,,6.10%,
564,ding-auto-balanced,CIFAR-10,ResNet-56,,"table 3, AFP-H",,7.41%,,,,,,,,,,0.0572,,,,,,,0.142,,,6.10%,
565,ding-auto-balanced,CIFAR-10,ResNet-56,,"table 3, AFP-I",,9.43%,,,,,,,,,,0.0414,,,,,,,0.142,,,6.10%,
561,ding-auto-balanced,CIFAR-10,VGG-Torch-CIFAR10,,"apparent contradiction in literature? Li et al use VGG-Torch-CIFAR10 (which also has dropout), while this paper says: ""The experiments in this section are based on a VGG-16 version same as (Li et al. 2016). Concretely, the overall convolutional architecture remains the same as (Simonyan and Zisserman 2014), while every convolutional layer is followed by a batch normalization (Ioffe and Szegedy 2015) layer."" Although there are already contradictory accounts (including arguably from Li et al) of what Li et al did.
-table 2, AFP-E",,7.06%,,,,,,,,,,0.0637,,,,,,,0.313,,,7.08%,
563,ding-auto-balanced,CIFAR-10,VGG-Torch-CIFAR10,,"apparent contradiction in literature? Li et al use VGG-Torch-CIFAR10 (which also has dropout), while this paper says: ""The experiments in this section are based on a VGG-16 version same as (Li et al. 2016). Concretely, the overall convolutional architecture remains the same as (Simonyan and Zisserman 2014), while every convolutional layer is fol- lowed by a batch normalization (Ioffe and Szegedy 2015) layer."" Although there are already contradictory accounts (including arguably from Li et al) of what Li et al did.
-table 2, AFP-F",,7.13%,,,,,,,,,,0.0583,,,,,,,0.313,,,7.08%,
556,ding-auto-balanced,MNIST,LeNet-5-Caffe,,"""We perform experiments on a version of LeNet-5 defined in (Yangqing 2014), which consists of two convolutional and two fully-connected layers. Since the two convolutional layers comprise 20 and 50 filters, respectively,""",,,,,,,,,,,,,,,,,,,,,,,
168,divnet,CIFAR-10,fc3072-1000-1000-1000-sigmoid,,,,,,,,,,,,,,,,,,,,,,,,,
162,divnet,MNIST,fc500-500-sigmoid,,,,,,,,,,,,,,,,,,,,,,,,,
167,divnet,MNIST-ROT,fc500-500-sigmoid,,,,,,,,,,,,,,,,,,,,,,,,,
342,early-brain-damage,UCI-Boston,fc3,,"multiple trials, but no stds / err bars",5,,,,,,,,,,,,,,,,,,,,,,
340,early-brain-damage,UCI-BreastCancer,fc10,,,5,,,,,,,,,,,,,,,,,,,,,,
341,early-brain-damage,UCI-Diabetes,fc5,,,5,,,,,,,,,,,,,,,,,,,,,,
350,eigenDamage,CIFAR-10,PreResNet-29+L1,,"for all these in table 1, ""We run each experiment five times, and present the mean and standard variance."" Not sure what ""standard variance"" is, but props for including it for not only test acc, but also ""Reduction in Weights (%)"" and ""Reduction in FLOPs (%)""",5,,,,,,,,,,,,,,,,,,,,,,
349,eigenDamage,CIFAR-10,ResNet-32,,,5,,,,,,,,,,,,,,,,,,,,,,
347,eigenDamage,CIFAR-10,VGG-19,,"IIRC, they just call it ""VGGNet"" in the text, but clarify in the tables",5,,,,,,,,,,,,,,,,,,,,,,
348,eigenDamage,CIFAR-10,VGG-19+L1,,,5,,,,,,,,,,,,,,,,,,,,,,
354,eigenDamage,CIFAR-100,PreResNet-29+L1,,,5,,,,,,,,,,,,,,,,,,,,,,
353,eigenDamage,CIFAR-100,ResNet-32,,,5,,,,,,,,,,,,,,,,,,,,,,
351,eigenDamage,CIFAR-100,VGG-19,,,5,,,,,,,,,,,,,,,,,,,,,,
352,eigenDamage,CIFAR-100,VGG-19+L1,,,5,,,,,,,,,,,,,,,,,,,,,,
355,eigenDamage,Tiny ImageNet,VGG-19,,,5,,,,,,,,,,,,,,,,,,,,,,
174,exploit-linear-structure,ImageNet,AlexNet,,only reports numbers for each layer (with associated change in error),,,,,,,,,,,,,,,,,,,,,,,
61,extreme-net-compress,CIFAR-100,VGG-Torch-CIFAR10-noDrop,,table 3,,,,,,,,,,,,,,,,,,,,,,,
63,extreme-net-compress,ImageNet,ResNet-34,,table 3,,,,,,-0.350%,,-0.040%,,,,,45.63%,,,,,,,,,,
540,extreme-net-compress,ImageNet,ResNet-34,,table 3,,,,,,-1.020%,,-0.300%,,,,,64.75%,,,,,,,,,,
541,extreme-net-compress,ImageNet,ResNet-34,,table 3,,,,,,-1.700%,,-0.440%,,,,,80.33%,,,,,,,,,,
542,extreme-net-compress,ImageNet,ResNet-34,,table 3,,,,,,-3.030%,,-1.220%,,,,,84.99%,,,,,,,,,,
62,extreme-net-compress,ImageNet,VGG-16,,table 3,,,,,,0.820%,,0.940%,,,,,56.99%,,,,,,,,,,
375,extreme-net-compress,ImageNet,VGG-16,,table 3,,,,,,-0.280%,,-0.070%,,,,,77.86%,,,,,,,,,,
376,extreme-net-compress,ImageNet,VGG-16,,table 3,,,,,,-1.060%,,-0.270%,,,,,81.35%,,,,,,,,,,
377,extreme-net-compress,ImageNet,VGG-16,,table 3,,,,,,-3.490%,,-2.030%,,,,,85.80%,,,,,,,,,,
239,face-prune,CASIA-WebFace,Yi's Face Network,,,,,,,,,,,,,,,,,,,,,,,,,
147,google-interchannel,CIFAR-10,TF-Example-CIFAR10,,"""We use standard networks provided by TensorFlow. For MNIST, it has 3-layer convolutional layers and achieves 99.5% accuracy when fully trained.""",,,,,,,,,,,,,,,,,,,,,,,
148,google-interchannel,ImageNet,Inception-v3,,,,,,,,,,,,,,,,,,,,,,,,,
149,google-interchannel,ImageNet,VGG-16n,,,,,,,,,,,,,,,,,,,,,,,,,
146,google-interchannel,MNIST,TF-Example-MNIST,,"""We use standard networks provided by TensorFlow. For MNIST, it has 3-layer convolutional layers and achieves 99.5% accuracy when fully trained.""",,,,,,,,,,,,,,,,,,,,,,,
50,google-state-of-sparsity,ImageNet,ResNet-50,Magnitude-v2,"this is the net at end of sec 5.2, with 80% unstructured sparsity, which is apparently SotA acc/size tradeoff. Not gonna type in all their results CSVs..... Also note that they only report this one number, with no std or anything for this net. They call this ""magnitude pruning v2"" in figure 5, which is where I got the method name",,,,76.52%,,-0.170%,,,,80.00%,,,,,76.69%,,,,,,,,
51,google-state-of-sparsity,WMT 2014 English-German,Transformer,,,,,,,,,,,,,,,,,,,,,,,,,
183,group-sparse-dnns,Covertype,fc50-50-20-7,,,,,,,,,,,,,,,,,,,,,,,,,
186,group-sparse-dnns,Digits,fc40-20,,,,,,,,,,,,,,,,,,,,,,,,,
182,group-sparse-dnns,MNIST,fc400-300-100-10,,,,,,,,,,,,,,,,,,,,,,,,,
180,group-sparse-dnns,SSD,fc40-40-30-11,,,,,,,,,,,,,,,,,,,,,,,,,
262,han-prune-quant-huff,ImageNet,CaffeNet,,"table 4, only pruning; baseline + new accuracies from table1 (""compressed"" acc includes quantization also, so might be somewhat pessimistic for pruning-only)
-they give orig params in KB; I used 1KB = 1000 / 4 = 250 params to convert to nparams",,42.78%,19.70%,,,,,,,,11.00%,,,,,,,60.000,,,,42.78%,19.73%
263,han-prune-quant-huff,ImageNet,VGG-16,,"table 5, only pruning; baseline + new accuracies from table1 (""compressed"" acc includes quantization also, so might be somewhat pessimistic for pruning-only)
-they give orig params in KB; I used 1KB = 1000 / 4 = 250 params to convert to nparams",,31.17%,10.91%,,,,,,,,7.50%,,,,,,,138.000,,,,31.50%,10.91%
269,han-prune-quant-huff,MNIST,LeNet-5,,they give orig params in KB; I used 1KB = 1000 / 4 = 250 params to convert to nparams,,0.74%,,,,,,,,,,,,,,,,0.430,,,,0.80%,
264,han-prune-quant-huff,MNIST,LeNet-300-100,,they give orig params in KB; I used 1KB = 1000 / 4 = 250 params to convert to nparams,,1.58%,,,,,,,,,,,,,,,,0.268,,,,1.64%,
120,hard-concrete,CIFAR-10,WRN-28-10,,,,,,,,,,,,,,,,,,,,,,,,,
121,hard-concrete,CIFAR-100,WRN-28-10,,,,,,,,,,,,,,,,,,,,,,,,,
119,hard-concrete,MNIST,LeNet-5-Caffe+800,,"they say lenet5, but also list layer sizes as 20-50-800-500, so...wut?

__NOTE__",,,,,,,,,,,,,,,,,,,,,,,
118,hard-concrete,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
311,he-reshaping,Switchboard English,fc2048x7,,"maybe RNN? just says ""The baseline DNN has 7 hidden layers of 2048 nodes per layer.""",,,,,,,,,,,,,,,,,,,,,,,
310,he-reshaping,TIMIT,L5-1024,,,,,,,,,,,,,,,,,,,,,,,,,
291,huang-prune-filters,CamVid,SegNet,,,,,,,,,,,,,,,,,,,,,,,,,
289,huang-prune-filters,CIFAR-10,ResNet-18,,"except ""The first max pooling layer in the official ResNet-18 network is removed to deal with the small resolution.""; using pytorch resnet; they say this has ""11M"" params by default",,,,,,-0.300%,,,,,,,,,,,,,,,1.320,,
305,huang-prune-filters,CIFAR-10,ResNet-18,,,,,,,,-1.700%,,,,,,,,,,,,,,,2.830,,
304,huang-prune-filters,CIFAR-10,ResNet-18,,also gives acc drops from pruning-filters at same (same-ish?) pruning amounts,,,,,,-1.000%,,,,,,,,,,,,,,,1.550,,
306,huang-prune-filters,CIFAR-10,ResNet-18,,,,,,,,-2.900%,,,,,,,,,,,,,,,4.170,,
288,huang-prune-filters,CIFAR-10,VGG-16,,"pytorch vgg16; but they say it has ""15M"" params in their table (but 3.1e8 flops)",,,,,,,,,,,,,,,,,,,,,,,
300,huang-prune-filters,CIFAR-10,VGG-16,,1 / (1 - .45); also compares to pruning-filters and gets less acc drop at (ostensibly?) same amount of pruning,,,,,,-0.600%,,,,,,,,,,,,,,,1.810,,
301,huang-prune-filters,CIFAR-10,VGG-16,,,,,,,,-1.100%,,,,,,,,,,,,,,,2.230,,
302,huang-prune-filters,CIFAR-10,VGG-16,,,,,,,,-1.900%,,,,,,,,,,,,,,,2.820,,
303,huang-prune-filters,CIFAR-10,VGG-16,,,,,,,,-3.400%,,,,,,,,,,,,,,,5.150,,
290,huang-prune-filters,Pascal VOC 2007,FCN-32s,,,,,,,,,,,,,,,,,,,,,,,,,
279,jaderberg-low-rank-conv,Combined Char Recognition Dataset,conv48-64-128-37,,,,,,,,,,,,,,,,,,,,,,,,,
602,L0-arm-binary,CIFAR-10,WRN-28-10,,,,,,,,,,,,,,,,,,,,,,,,,
603,L0-arm-binary,CIFAR-100,WRN-28-10,,,,,,,,,,,,,,,,,,,,,,,,,
600,L0-arm-binary,MNIST,fc300-100,,,,,,,,,,,,,,,,,,,,,,,,,
601,L0-arm-binary,MNIST,LeNet-5-Caffe,,,,,,,,,,,,,,,,,,,,,,,,,
172,learning-both,ImageNet,CaffeNet,,"table 4; slightly ambiguous whether this is AlexNet or CaffeNet. Also note that the acc numbers are not given; they just say ""AlexNet can be pruned to 1/9 of its original size without impacting accuracy""",,,,57.23%,,0.000%,80.33%,0.000%,,89.00%,,,70.00%,,57.22%,,80.27%,61.000,1.500,,,,
402,learning-both,ImageNet,CaffeNet,,"from dots in fig5, so approx (using best settings)",,,,,,,,0.001%,,87.00%,,,,,57.22%,,80.27%,61.000,,,,,
404,learning-both,ImageNet,CaffeNet,,"from dots in fig5, so approx (using best settings)",,,,,,,,-0.050%,,90.00%,,,,,57.22%,,80.27%,61.000,,,,,
405,learning-both,ImageNet,CaffeNet,,"from dots in fig5, so approx (using best settings)",,,,,,,,-0.400%,,92.00%,,,,,57.22%,,80.27%,61.000,,,,,
406,learning-both,ImageNet,CaffeNet,,"from dots in fig5, so approx (using best settings)",,,,,,,,-0.600%,,93.00%,,,,,57.22%,,80.27%,61.000,,,,,
407,learning-both,ImageNet,CaffeNet,,"from dots in fig5, so approx (using best settings)",,,,,,,,-4.200%,,96.00%,,,,,57.22%,,80.27%,61.000,,,,,
408,learning-both,ImageNet,CaffeNet,,"from dots in fig5, so approx (using best settings)",,,,,,,,-1.050%,,94.00%,,,,,57.22%,,80.27%,61.000,,,,,
409,learning-both,ImageNet,CaffeNet,,"from dots in fig5, so approx (using best settings)",,,,,,,,-2.000%,,95.00%,,,,,57.22%,,80.27%,61.000,,,,,
173,learning-both,ImageNet,VGG-16,,table 5; they don't say the accuracy; pretty sure their weights/flops nums in the bottom row are for the original network,,,,,,,,,,92.50%,,,89.00%,,,,,138.000,30.900,,,,
171,learning-both,MNIST,LeNet-5,,"p4: only footnote saying they used alexnet from model zoo, so presumably this is original lenet-5",,,,,,,,,,,,,,,,,,,,,,,
170,learning-both,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
286,learning-compression,CIFAR-10,ResNet-32,,"they cite ""Deep residual learning for image recognition.""",,7.32%,,,,,,,0.0693,,,,,,92.28%,,,0.460,,,,,
513,learning-compression,CIFAR-10,ResNet-32,,"they cite ""Deep residual learning for image recognition.""",,7.88%,,,,,,,0.0462,,,,,,92.28%,,,0.460,,,,,
514,learning-compression,CIFAR-10,ResNet-32,,"they cite ""Deep residual learning for image recognition.""",,9.26%,,,,,,,0.0231,,,,,,92.28%,,,0.460,,,,,
515,learning-compression,CIFAR-10,ResNet-32,,"they cite ""Deep residual learning for image recognition.""",,10.74%,,,,,,,0.0139,,,,,,92.28%,,,0.460,,,,,
512,learning-compression,CIFAR-10,ResNet-56,,"they cite ""Deep residual learning for image recognition.""",,6.92%,,,,,,,0.1273,,,,,,93.14%,,,0.850,,,,,
516,learning-compression,CIFAR-10,ResNet-56,,"they cite ""Deep residual learning for image recognition.""",,6.67%,,,,,,,0.0849,,,,,,93.14%,,,0.850,,,,,
517,learning-compression,CIFAR-10,ResNet-56,,"they cite ""Deep residual learning for image recognition.""",,7.51%,,,,,,,0.0424,,,,,,93.14%,,,0.850,,,,,
518,learning-compression,CIFAR-10,ResNet-56,,"they cite ""Deep residual learning for image recognition.""",,8.21%,,,,,,,0.0255,,,,,,93.14%,,,0.850,,,,,
287,learning-compression,CIFAR-10,ResNet-110,,"they cite ""Deep residual learning for image recognition.""",,6.30%,,,,,,,0.2580,,,,,,93.30%,,,1.700,,,,,
519,learning-compression,CIFAR-10,ResNet-110,,"they cite ""Deep residual learning for image recognition.""",,6.50%,,,,,,,0.1720,,,,,,93.30%,,,1.700,,,,,
520,learning-compression,CIFAR-10,ResNet-110,,"they cite ""Deep residual learning for image recognition.""",,7.61%,,,,,,,0.0516,,,,,,93.30%,,,1.700,,,,,
521,learning-compression,CIFAR-10,ResNet-110,,"they cite ""Deep residual learning for image recognition.""",,6.93%,,,,,,,0.0860,,,,,,93.30%,,,1.700,,,,,
285,learning-compression,MNIST,LeNet-5,,,,,,,,,,,,,,,,,,,,,,,,,
284,learning-compression,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
253,learning-num-neurons,ICDAR,Dec3,,made up convnet,,,,,,,,,,,,,,,,,,,,,,,
251,learning-num-neurons,ImageNet,BNetC,,VGG-16-like,,,,,,,,,,,,,,,,,,,,,,,
252,learning-num-neurons,ImageNet,Dec8,,made up convnet,,,,,,,,,,,,,,,,,,,,,,,
277,lempitsky-cp-decomp,???,CharNet,,,,,,,,,,,,,,,,,,,,,,,,,
278,lempitsky-cp-decomp,ImageNet,CaffeNet,,"they got way better results with Jaderberg 2014b's method than original authors did: ""Although (Jaderberg et al., 2014b) mentions that application of their approach to the second layer of the OverFeat architecture yields a 2× speed-up, our colleagues at Yandex have discovered that a far greater speed-up with (Jaderberg et al., 2014b) can be reached, at least for AlexNet. In particular, our experiments with (Jaderberg et al., 2014b) on AlexNet have showed that the second convolutional layer of AlexNet can be accelerated by the factor of 6.6× at the cost of ≈ 1% accuracy loss via Scheme 2 and data optimization as described in (Jaderberg et al., 2014b)""; reason I think they're using caffenet is that ""As a baseline we use a pre-trained model shipped with Caffe."" in section ""4.2 AlexNet""; no numbers here cuz ""report the speed-up compared to the CPU timings of the original model"", so no flop comparison and no size comparison unless I do math to convert between pruning just ""the second convolutional layer"" and overall size reduction.
-No numbers because only report speedup for a given layer (seemingly; a lot of ambiguity)
-also note that jaderberg (below) just plain doesn't use the same CNN, so not sure what to take away from this comparison

__NOTE__",,,,,,,,-0.500%,,,,,,,,,,,,,,,
465,lempitsky-fast-convnets,ImageNet,CaffeNet,Fixed,"Table 1, Training with fixed sparsity patterns, accelerating just 2nd conv layer",,,,,,-0.160%,,,,80.00%,,,,,,,,,,,5.000,,
466,lempitsky-fast-convnets,ImageNet,CaffeNet,Groupwise,"Table1, Group-wise sparsification + Fine-tuning, accelerating just 2nd conv layer",,,,,,-1.130%,,,,90.00%,,,,,,,,,,,10.000,,
464,lempitsky-fast-convnets,ImageNet,CaffeNet,Fixed,"Table 1, Training with fixed sparsity patterns, accelerating just 2nd conv layer.",,,,,,-0.820%,,,,88.00%,,,,,,,,,,,8.330,,
467,lempitsky-fast-convnets,ImageNet,CaffeNet,Groupwise,"Table1, Group-wise sparsification + Fine-tuning, accelerating just 2nd conv layer",,,,,,-0.430%,,,,80.00%,,,,,,,,,,,5.000,,
468,lempitsky-fast-convnets,ImageNet,CaffeNet,Groupwise,"Table1, Group-wise sparsification + Fine-tuning, accelerating just 2nd conv layer",,,,,,-0.110%,,,,70.00%,,,,,,,,,,,3.330,,
469,lempitsky-fast-convnets,ImageNet,CaffeNet,Groupwise,"Table1, Group-wise sparsification + Fine-tuning, accelerating just 2nd conv layer",,,,,,0.090%,,,,60.00%,,,,,,,,,,,2.500,,
470,lempitsky-fast-convnets,ImageNet,CaffeNet,Gradual,"Table 1, Gradual group-wise sparsification, accelerating just 2nd conv layer",,,,,,-0.280%,,,,89.00%,,,,,,,,,,,9.000,,
471,lempitsky-fast-convnets,ImageNet,CaffeNet,Gradual,"Table 1, Gradual group-wise sparsification, accelerating just 2nd conv layer",,,,,,-1.070%,,,,95.00%,,,,,,,,,,,20.000,,
474,lempitsky-fast-convnets,ImageNet,CaffeNet,Groupwise,"Table1, Group-wise sparsification + Fine-tuning, accelerating 2nd and 3rd conv layers",,,,,,-1.500%,,,,80.00%,,,,,,,,,,,5.000,,
472,lempitsky-fast-convnets,ImageNet,CaffeNet,Fixed,"Table 1, Training with fixed sparsity patterns, accelerating 2nd and 3rd conv layers",,,,,,-1.540%,,,,88.00%,,,,,,,,,,,8.700,,
473,lempitsky-fast-convnets,ImageNet,CaffeNet,Fixed,"Table 1, Training with fixed sparsity patterns, accelerating 2nd and 3rd conv layers",,,,,,0.530%,,,,46.00%,,,,,,,,,,,1.900,,
476,lempitsky-fast-convnets,ImageNet,CaffeNet,Groupwise,"Table1, Group-wise sparsification + Fine-tuning, accelerating 2nd and 3rd conv layers",,,,,,-0.570%,,,,50.00%,,,,,,,,,,,2.000,,
475,lempitsky-fast-convnets,ImageNet,CaffeNet,Groupwise,"Table1, Group-wise sparsification + Fine-tuning, accelerating 2nd and 3rd conv layers",,,,,,-1.170%,,,,70.00%,,,,,,,,,,,3.330,,
477,lempitsky-fast-convnets,ImageNet,CaffeNet,Gradual,"Table 1, Gradual group-wise sparsification, accelerating 2nd and 3rd conv layers",,,,,,-1.040%,,,,88.00%,,,,,,,,,,,8.500,,
478,lempitsky-fast-convnets,ImageNet,CaffeNet,Fixed,"Table 1, Training with fixed sparsity patterns, accelerating all 5 conv layers",,,,,,-1.340%,,,,66.00%,,,,,,,,,,,3.000,,
479,lempitsky-fast-convnets,ImageNet,CaffeNet,Fixed,"Table 1, Training with fixed sparsity patterns, accelerating all 5 conv layers",,,,,,-1.430%,,,,69.00%,,,,,,,,,,,3.200,,
480,lempitsky-fast-convnets,ImageNet,CaffeNet,Fixed,"Table 1, Training with fixed sparsity patterns, accelerating 2nd and 3rd conv layers",,,,,,-0.360%,,,,65.00%,,,,,,,,,,,2.900,,
152,lempitsky-fast-convnets,ImageNet,VGG-19,,,,,,,,,,,,,,,,,,,,,,,,,
150,lempitsky-fast-convnets,MNIST,LeNet-5,,"seems to actually be lenet5 ""We trained the LeNet architecture on the MNIST dataset from random initialization""",,,,,,,,,,,,,,,,,,,,,,,
169,liu-sparse-conv,ImageNet,CaffeNet,,they just don't say what their accuracy is __NOTE__,,,,,,,,,,,,,,,,,,,,,,,
358,local-competition,CIFAR-10,conv64-64-fc384-192,,"""we employ a computationally light convolutional architecture proposed by Alex Krizhevsky, which we dub ConvNet. The architecture comprises two layers with 64 5x5 kernels (feature maps), followed by two dense layers with 384 and 192 units respectively.""

__NOTE__",,,,,,,,,,,,,,,,,,,,,,,
357,local-competition,MNIST,LeNet-5-Caffe,,,,,,,,,,,,,,,,,,,,,,,,,
356,local-competition,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
73,lottery-ticket,CIFAR-10,Toy Convnets,,,,,,,,,,,,,,,,,,,,,,,,,
74,lottery-ticket,CIFAR-10,VGG-16-AvgPool,,,,,,,,,,,,,,,,,,,,,,,,,
72,lottery-ticket,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
41,lottery-ticket-followup,CIFAR-10,ResNet-18,,,,,,,,,,,,,,,,,,,,,,,,,
40,lottery-ticket-followup,CIFAR-10,VGG-19,,,,,,,,,,,,,,,,,,,,,,,,,
43,lottery-ticket-followup,ImageNet,ResNet-50,,"using means from last row of table 10 (late resetting epoch=10). ""The original network reaches top-1 accuracy of 76.14±0.08%"".",,,,76.25%,,,,,,30.00%,,,,,76.14%,,,,,,,,
443,lottery-ticket-followup,ImageNet,ResNet-50,,"using means from last row of table 10 (late resetting epoch=10). ""The original network reaches top-1 accuracy of 76.14±0.08%"".",,,,76.16%,,,,,,50.00%,,,,,76.14%,,,,,,,,
444,lottery-ticket-followup,ImageNet,ResNet-50,,"using means from last row of table 10 (late resetting epoch=10). ""The original network reaches top-1 accuracy of 76.14±0.08%"".",,,,75.93%,,,,,,70.00%,,,,,76.14%,,,,,,,,
445,lottery-ticket-followup,ImageNet,ResNet-50,,"using means from last row of table 10 (late resetting epoch=10). ""The original network reaches top-1 accuracy of 76.14±0.08%"".",,,,75.54%,,,,,,80.00%,,,,,76.14%,,,,,,,,
446,lottery-ticket-followup,ImageNet,ResNet-50,,"using means from last row of table 10 (late resetting epoch=10). ""The original network reaches top-1 accuracy of 76.14±0.08%"".",,,,73.66%,,,,,,90.00%,,,,,76.14%,,,,,,,,
42,lottery-ticket-followup,MNIST,LeNet-5,,,,,,,,,,,,,,,,,,,,,,,,,
101,lstm-group-lasso,PTB,Custom stacked LSTMs,,they also compare to same arch trained from scratch and find that theirs works better,,,,,,,,,,,,,,,,,,,,,,,
100,lstm-group-lasso,SQuaD,BiDaF,,,,,,,,,,,,,,,,,,,,,,,,,
105,lstm-group-lasso,SQuaD,Variational RHN + WT,,,,,,,,,,,,,,,,,,,,,,,,,
338,memory-bounded-convnets,CIFAR-10,CIFAR-10 Quick,,,,,,,,,,,,,,,,,,,,,,,,,
339,memory-bounded-convnets,ImageNet,CaffeNet,,"called ""Caffe Version"" of alexnet in fig1; note that table on p1 is including sparsity overhead; had to do a bunch of math to determine nparams kept based on what they report on p8",,,,55.60%,,,80.40%,,8.7040,,14.00%,,,,57.28%,,80.44%,,,,,,
337,memory-bounded-convnets,MNIST,LeNet-5-Caffe,,"Probably lenet5-caffe but they just say lenet: ""We use as a target for our regularization the baseline networks provided with that distribution, Lenet [13] and CIFAR-10 Quick [22]."" plus earlier in the paragraph ""Our regularization updates were implemented as a modification to Caffe""",,,,,,,,,,,,,,,,,,,,,,,
49,mit-coreset-pruning,MNIST,Various FC Networks,,,,,,,,,,,,,,,,,,,,,,,,,
273,more-is-less,???,ResNet-20,,"table 4, explicitly says pre-activation ResNet-20; under ""Experiments on CIFAR-10 and CIFAR-100"", but unclear which one; err rates suggest cifar10
",,,,,,,,,,,,,,,,,,,,,,,
274,more-is-less,???,ResNet-32,,"table 4, under ""Experiments on CIFAR-10 and CIFAR-100"", but unclear which one; err rates suggest cifar10",,,,,,,,,,,,,,,,,,,,,,,
275,more-is-less,???,ResNet-44,,"table 4, under ""Experiments on CIFAR-10 and CIFAR-100"", but unclear which one; err rates suggest cifar10",,,,,,,,,,,,,,,,,,,,,,,
222,more-is-less,CIFAR-10,PreResNet-110,,table5; or at least they cite the 2016 resnet paper,,,,,,,,,,,,,,,,,,,,,,,
223,more-is-less,CIFAR-10,PreResNet-164,,table5; or at least they cite the 2016 resnet paper,,,,,,,,,,,,,,,,,,,,,,,
224,more-is-less,CIFAR-10,WRN-22-8,,,,,,,,,,,,,,,,,,,,,,,,,
225,more-is-less,CIFAR-10,WRN-28-2,,,,,,,,,,,,,,,,,,,,,,,,,
226,more-is-less,CIFAR-10,WRN-40-1,,,,,,,,,,,,,,,,,,,,,,,,,
227,more-is-less,CIFAR-10,WRN-40-2,,,,,,,,,,,,,,,,,,,,,,,,,
228,more-is-less,CIFAR-10,WRN-40-4,,,,,,,,,,,,,,,,,,,,,,,,,
229,more-is-less,CIFAR-10,WRN-52-1,,,,,,,,,,,,,,,,,,,,,,,,,
230,more-is-less,CIFAR-100,PreResNet-164,,or at least they cite the 2016 resnet paper,,,,,,,,,,,,,,,,,,,,,,,
231,more-is-less,CIFAR-100,WRN-16-4,,,,,,,,,,,,,,,,,,,,,,,,,
232,more-is-less,CIFAR-100,WRN-22-8,,,,,,,,,,,,,,,,,,,,,,,,,
233,more-is-less,CIFAR-100,WRN-40-1,,,,,,,,,,,,,,,,,,,,,,,,,
234,more-is-less,CIFAR-100,WRN-40-2,,,,,,,,,,,,,,,,,,,,,,,,,
235,more-is-less,CIFAR-100,WRN-40-4,,,,,,,,,,,,,,,,,,,,,,,,,
236,more-is-less,CIFAR-100,WRN-52-1,,,,,,,,,,,,,,,,,,,,,,,,,
237,more-is-less,ImageNet,ResNet-18,,"table 7; reports ""34.6%"" under ""Speed-up"" column, which seemingly means 1.346x",,33.67%,13.06%,,,,,,,,,,,,69.98%,,89.24%,,,,1.346,,
238,more-is-less,ImageNet,ResNet-34,,"table 7; reports ""24.8%"" under ""Speed-up"" column, which seemingly means 1.248x",,27.01%,8.81%,,,,,,,,,,,,73.42%,,91.36%,,,,1.248,,
158,net-surgery,ImageNet,CaffeNet,,"ambiguous if alexnet; "" all the reference models are trained by the GPU implementation of Caffe package [12] with .prototxt files provided by the community""

__NOTE__",,,,56.91%,,,80.01%,,3.4500,,,,,,56.58%,,,61.000,,,,,
164,net-surgery,MNIST,LeNet-5-Caffe,,"ambiguous if lenet5; "" all the reference models are trained by the GPU implementation of Caffe package [12] with .prototxt files provided by the community""",,,,,,,,,0.4310,,,,,,,,,,,,,,
163,net-surgery,MNIST,LeNet-300-100,,this one they say they implemented themselves,,,,,,,,,0.2670,,,,,,,,,,,,,,
117,net-trim,MNIST,???,,some CNN model they don't describe,,,,,,,,,,,,,,,,,,,,,,,
111,net-trim,MNIST,fc300-300,,trained on 10k examples,,,,,,,,,,,,,,,,,,,,,,,
114,net-trim,MNIST,fc300-300,,,,,,,,,,,,,,,,,,,,,,,,,
112,net-trim,MNIST,fc300-500-300,,trained on 30k examples,,,,,,,,,,,,,,,,,,,,,,,
115,net-trim,MNIST,fc300-500-300,,,,,,,,,,,,,,,,,,,,,,,,,
113,net-trim,MNIST,fc300-1000-300,,trained on 60k examples,,,,,,,,,,,,,,,,,,,,,,,
116,net-trim,MNIST,fc300-1000-300,,,,,,,,,,,,,,,,,,,,,,,,,
48,net-trim-v2,CIFAR-10,Net-Trim-ConvNet,,,,,,,,,,,,,,,,,,,,,,,,,
46,net-trim-v2,MNIST,fc1000-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
47,net-trim-v2,MNIST,LeNet-5,,no mention of caffe so presumably this is actually lenet5; ,,,,,,,,,,,,,,,,,,,,,,,
161,net-trimming-apoz,ImageNet,VGG-16,,,,,,71.05%,,,90.30%,,,,,,,,68.36%,,88.44%,,,1.96,,,
398,net-trimming-apoz,ImageNet,VGG-16,,,,,,70.55%,,,90.03%,,,,,,,,68.36%,,88.44%,,,2.34,,,
399,net-trimming-apoz,ImageNet,VGG-16,,,,,,70.17%,,,89.69%,,,,,,,,68.36%,,88.44%,,,2.70,,,
400,net-trimming-apoz,ImageNet,VGG-16,,,,,,71.02%,,,90.30%,,,,,,,,68.36%,,88.44%,,,2.00,,,
401,net-trimming-apoz,ImageNet,VGG-16,,,,,,70.88%,,,90.04%,,,,,,,,68.36%,,88.44%,,,2.11,,,
160,net-trimming-apoz,MNIST,LeNet-5,,,,,,,,,,,,,,,,,,,,,,,,,
82,network-slimming,CIFAR-10,DenseNet-40,,,,,,,,,,,,,,,,,,,,,,,,,
56,network-slimming,CIFAR-10,PreResNet-164,,"“a 164-layer pre-activation ResNet with bottleneck structure (ResNet-164) [15] is used”; and yet at the start of sec 4.2 the cite [14], which is the original resnet paper

__NOTE__",,,,,,,,,,,,,,,,,,,,,,,
57,network-slimming,CIFAR-10,VGG-netslim,,"contradiction between paper and source code? See https://github.com/liuzhuang13/slimming/blob/master/models/vgg.lua; paper just says ""For our experiment a variation of the original VGGNet for CIFAR dataset is taken from [36]."" which is torch vgg16 for cifar10; but src code says: ""-- This is a modified version of VGG network in -- https://github.com/szagoruyko/cifar.torch -- Modifications: --  * removed dropout --  * last nn.Linear layers substituted with convolutional layers --    and avg-pooling""",,,,,,,,,,,,,,,,,,,,,,,
83,network-slimming,CIFAR-100,DenseNet-40,,,,,,,,,,,,,,,,,,,,,,,,,
81,network-slimming,CIFAR-100,PreResNet-164,,“a 164-layer pre-activation ResNet with bottleneck structure (ResNet-164) [15] is used”,,,,,,,,,,,,,,,,,,,,,,,
80,network-slimming,CIFAR-100,VGG-netslim,,,,,,,,,,,,,,,,,,,,,,,,,
55,network-slimming,ImageNet,VGG-A+BN-noDrop,,,,,,,,,,,,,,,,,,,,,,,,,
60,network-slimming,MNIST,fc500-300-100,,"""same fully connected network as [SSL paper]""",,,,,,,,,,,,,,,,,,,,,,,
84,network-slimming,SVHN,DenseNet-40,,,,,,,,,,,,,,,,,,,,,,,,,
59,network-slimming,SVHN,PreResNet-164,,“a 164-layer pre-activation ResNet with bottleneck structure (ResNet-164) [15] is used”,,,,,,,,,,,,,,,,,,,,,,,
58,network-slimming,SVHN,VGG-netslim,,,,,,,,,,,,,,,,,,,,,,,,,
198,nisp,CIFAR-10,Cifar-net,,,,,,,,,,,,,,,,,,,,,,,,,
203,nisp,CIFAR-10,ResNet-56,,table 1 p7,,,,,,-0.030%,,,,42.60%,,,43.61%,,,,,,,,,,
204,nisp,CIFAR-10,ResNet-110,,table 1 p7,,,,,,-0.180%,,,,43.25%,,,43.78%,,,,,,,,,,
199,nisp,ImageNet,AlexNet,,table 1 p7; probably actually caffenet,,,,,,,,-1.430%,,33.77%,,,67.85%,,,,,,,,,,
201,nisp,ImageNet,AlexNet,,table 1 p7; probably actually caffenet,,,,,,,,-0.970%,,1.96%,,,62.69%,,,,,,,,,,
410,nisp,ImageNet,AlexNet,,table 1 p7; probably actually caffenet,,,,,,,,-0.540%,,2.91%,,,53.70%,,,,,,,,,,
411,nisp,ImageNet,AlexNet,,table 1 p7; probably actually caffenet,,,,,,,,0.000%,,47.09%,,,40.12%,,,,,,,,,,
200,nisp,ImageNet,GoogLeNet,,table 1 p7,,,,,,,,-0.210%,,33.76%,,,58.34%,,,,,,,,,,
205,nisp,ImageNet,ResNet-34,,table 1 p7,,,,,,,,-0.280%,,27.14%,,,27.32%,,,,,,,,,,
412,nisp,ImageNet,ResNet-34,,table 1 p7,,,,,,,,-0.920%,,43.68%,,,43.76%,,,,,,,,,,
206,nisp,ImageNet,ResNet-50,,table 1 p7,,,,,,,,-0.210%,,27.12%,,,27.31%,,,,,,,,,,
413,nisp,ImageNet,ResNet-50,,table 1 p7,,,,,,,,-0.840%,,43.82%,,,44.01%,,,,,,,,,,
197,nisp,MNIST,LeNet-5,,,,,,,,,,,,,,,,,,,,,,,,,
243,nvidia-taylor-pruning,Flowers-102,CaffeNet,,,,,,,,,,,,,,,,,,,,,,,,,
244,nvidia-taylor-pruning,ImageNet,VGG-16,,,,,,,,,,,,,,,,,,,,,,,,,
245,nvidia-taylor-pruning,nvGesture,R3DCNN,,,,,,,,,,,,,,,,,,,,,,,,,
106,openai-block-sparse,???,PixelCNN++,,,,,,,,,,,,,,,,,,,,,,,,,
107,openai-block-sparse,Amazon Reviews,Small-World LSTM,,,,,,,,,,,,,,,,,,,,,,,,,
109,openai-block-sparse,IMDB,Small-World LSTM,,,,,,,,,,,,,,,,,,,,,,,,,
108,openai-block-sparse,Stanford Sentiment Treebank,Small-World LSTM,,,,,,,,,,,,,,,,,,,,,,,,,
110,openai-block-sparse,Yelp,Small-World LSTM,,,,,,,,,,,,,,,,,,,,,,,,,
175,optimal-brain-damage,1990 Handwritten Digits,???,,,,,,,,,,,,,,,,,,,,,,,,,
346,optimal-brain-surgeon,???,???,,"""a three-layer NETtalk network. While Sejnowski and Rosenberg [1] used 18,000 weights, we began with just 5,546 weights""",,,,,,,,,,,,,,,,,,,,,,,
343,optimal-brain-surgeon,MONK1,fc3,,,,,,,,,,,,,,,,,,,,,,,,,
344,optimal-brain-surgeon,MONK2,fc3,,,,,,,,,,,,,,,,,,,,,,,,,
345,optimal-brain-surgeon,MONK3,fc3,,,,,,,,,,,,,,,,,,,,,,,,,
332,pan-dropneuron,MNIST,autoenc-fc128-64-128,,,,,,,,,,,,,,,,,,,,,,,,,
333,pan-dropneuron,MNIST,LeNet-5,,,,,,,,,,,,,,,,,,,,,,,,,
68,pcas,CamVid,SegNet,,table2,,,,,,,,,,,,,,,,,,,,,,,
64,pcas,CIFAR-10,ResNet-56,,table1,,,,93.58%,,0.540%,,,0.3900,53.70%,,0.0560,54.80%,,,,,,,,,,
65,pcas,CIFAR-100,ResNet-50,,"table1; yes, seemingly contradicts their own originalMParams for this same model on ImageNet",,,,73.84%,,-0.620%,,,4.0200,76.50%,,0.4750,66.30%,,,,,,,,,,
67,pcas,ImageNet,ResNet-50,,"table1; yes, seemingly contradicts their own originalMParams for this same model on ImageNet",,,,72.68%,,-0.040%,91.09%,0.030%,12.4700,51.20%,,3.3400,56.70%,,,,,,,,,,
66,pcas,ImageNet,VGG-16,,table1,,,,69.41%,,1.000%,89.22%,0.850%,128.9500,6.80%,,8.5900,72.20%,,,,,,,,,,
378,pcas,ImageNet,VGG-16,,table1,,,,68.83%,,0.420%,88.82%,0.450%,128.0500,7.40%,,7.4900,75.80%,,,,,,,,,,
379,pcas,ImageNet,VGG-16,,table1,,,,68.18%,,-0.230%,88.39%,0.020%,127.2300,8.00%,,6.4500,79.20%,,,,,,,,,,
359,peng-collaborative,CIFAR-10,ResNet-56,CCP,,,,,,,-0.040%,,,,,,,47.00%,,93.50%,,,,,,,,
436,peng-collaborative,CIFAR-10,ResNet-56,CCP,,,,,,,-0.080%,,,,,,,52.60%,,93.50%,,,,,,,,
437,peng-collaborative,CIFAR-10,ResNet-56,CCP-AC,"""to provide a fair comparison, we introduce a variant of our CCP algorithm, where an auxiliary classifier is inserted into the intermediate layer^2"". Telling us about this in the results, and the ""fair"" is to provide an improvement, not handicap",,,,,,0.190%,,,,,,,47.00%,,93.50%,,,,,,,,
360,peng-collaborative,ImageNet,ResNet-50,CCP,,,,,,,-0.650%,,-0.250%,,,,,48.80%,,76.15%,,92.87%,,,,,,
434,peng-collaborative,ImageNet,ResNet-50,CCP,,,,,,,-0.940%,,-0.450%,,,,,54.10%,,76.15%,,92.87%,,,,,,
435,peng-collaborative,ImageNet,ResNet-50,CCP-AC,,,,,,,-0.830%,,-0.330%,,,,,54.10%,,76.15%,,92.87%,,,,,,
240,perforated-cnns,CIFAR-10,NIN,,,,,,,,,,,,,,,,,,,,,,,,,
241,perforated-cnns,ImageNet,AlexNet,,,,,,,,,,-2.300%,,,,,,,,,80.40%,,0.500,,2.100,,
414,perforated-cnns,ImageNet,AlexNet,,,,,,,,,,-6.100%,,,,,,,,,80.40%,,0.500,,3.500,,
415,perforated-cnns,ImageNet,AlexNet,,,,,,,,,,-6.200%,,,,,,,,,80.40%,,0.500,,3.400,,
416,perforated-cnns,ImageNet,AlexNet,,,,,,,,,,-9.900%,,,,,,,,,80.40%,,0.500,,4.400,,
417,perforated-cnns,ImageNet,AlexNet,,,,,,,,,,-2.000%,,,,,,,,,80.40%,,0.500,,2.000,,
418,perforated-cnns,ImageNet,AlexNet,,,,,,,,,,-3.200%,,,,,,,,,80.40%,,0.500,,2.600,,
242,perforated-cnns,ImageNet,VGG-16,,,,,,,,,,-1.100%,,,,,,,,,89.90%,,15.000,,1.800,,
419,perforated-cnns,ImageNet,VGG-16,,,,,,,,,,-3.700%,,,,,,,,,89.90%,,15.000,,2.900,,
420,perforated-cnns,ImageNet,VGG-16,,,,,,,,,,-7.300%,,,,,,,,,89.90%,,15.000,,4.700,,
421,perforated-cnns,ImageNet,VGG-16,,,,,,,,,,-5.500%,,,,,,,,,89.90%,,15.000,,4.000,,
422,perforated-cnns,ImageNet,VGG-16,,,,,,,,,,-6.800%,,,,,,,,,89.90%,,15.000,,2.800,,
423,perforated-cnns,ImageNet,VGG-16,,,,,,,,,,-2.500%,,,,,,,,,89.90%,,15.000,,1.900,,
142,pruning-filters,CIFAR-10,ResNet-56,,,,6.90%,,,,,,,0.7700,,,0.1120,,,93.04%,,,0.850,0.125,,,,
494,pruning-filters,CIFAR-10,ResNet-56,,,,6.94%,,,,,,,0.7300,,,0.0910,,,93.04%,,,0.850,0.125,,,,
143,pruning-filters,CIFAR-10,ResNet-110,,,,6.45%,,,,,,,1.6800,,,0.2130,,,93.53%,,,1.720,0.253,,,,
495,pruning-filters,CIFAR-10,ResNet-110,,,,6.70%,,,,,,,1.1600,,,0.1550,,,93.53%,,,1.720,0.253,,,,
141,pruning-filters,CIFAR-10,VGG-Torch-CIFAR10,,"Unsure what to make of this. ""We use the model described in Zagoruyko (2015) but add Batch Normalization (Ioffe & Szegedy (2015)"", but this model already has batchnorm.... Also dai-info-bottleneck says their model is original VGG with just smaller fc layers, plus they also ""further remove one additional fully-connected layer"". No src code available so unclear what they did",,6.60%,,,,,,,5.4000,,,0.2060,,,93.25%,,,15.000,0.313,,,,
145,pruning-filters,ImageNet,ResNet-34,,,,27.44%,,,,,,,19.9000,,,3.0800,,,73.23%,,,21.600,3.640,,,,
496,pruning-filters,ImageNet,ResNet-34,,,,27.83%,,,,,,,19.3000,,,2.7600,,,73.23%,,,21.600,3.640,,,,
497,pruning-filters,ImageNet,ResNet-34,,,,27.52%,,,,,,,20.1000,,,3.3700,,,73.23%,,,21.600,3.640,,,,
37,rethinking-net-pruning,CIFAR-10,???,,"table 8, vs lottery ticket. They use same ""VGG-16"" model as lottery ticket open review submission, but that paper says at the very end of the paper in ""Appendix H: EXPERIMENT DETAILS FOR VGG16 AND VGG19 ON CIFAR10"" that ""The versions use were modified by Anonymous (2019b) for CIFAR10"", where that reference is the OpenReview version of rethinking-net-pruning, which doesn't (including in that version) seem to uniquely point to a particular network (though maybe src code would disambiguate?)",,,,,,,,,,,,,,,,,,,,,,,
28,rethinking-net-pruning,CIFAR-10,DenseNet-40,,"table4, vs slimming",,,,,,,,,,,,,,,,,,,,,,,
34,rethinking-net-pruning,CIFAR-10,DenseNet-BC-100,,"table6, vs han",,,,,,,,,,,,,,,,,,,,,,,
33,rethinking-net-pruning,CIFAR-10,PreResNet-110,,"table6, vs han",,,,,,,,,,,,,,,,,,,,,,,
27,rethinking-net-pruning,CIFAR-10,PreResNet-164,,"table4, vs slimming",,,,,,,,,,,,,,,,,,,,,,,
21,rethinking-net-pruning,CIFAR-10,ResNet-56,Scratch-B,"table1, vs Li et al",,,,93.09%,,,,,0.7700,,,0.1120,,,93.14%,,,,,,,,
38,rethinking-net-pruning,CIFAR-10,ResNet-56,,"table 8, vs ticket; don't think it makes sense to include this table in comparative results since it's more of an ablation study and doesn't use scratch-b",,,,,,,,,,,,,,,93.14%,,,,,,,,
531,rethinking-net-pruning,CIFAR-10,ResNet-56,Scratch-B,"table1, vs Li et al",,,,93.05%,,,,,0.7300,,,0.0910,,,93.14%,,,,,,,,
22,rethinking-net-pruning,CIFAR-10,ResNet-110,Scratch-B,"table1, vs Li et al",,,,93.22%,,,,,1.6800,,,0.2130,,,93.14%,,,,,,,,
39,rethinking-net-pruning,CIFAR-10,ResNet-110,,"table 8, vs ticket; don't think it makes sense to include this table in comparative results since it's more of an ablation study and doesn't use scratch-b",,,,,,,,,,,,,,,,,,,,,,,
532,rethinking-net-pruning,CIFAR-10,ResNet-110,Scratch-B,"table1, vs Li et al",,,,93.60%,,,,,1.1600,,,0.1550,,,93.14%,,,,,,,,
26,rethinking-net-pruning,CIFAR-10,VGG-19,,"table4, vs slimming",,,,,,,,,,,,,,,,,,,,,,,
20,rethinking-net-pruning,CIFAR-10,VGG-Torch-CIFAR10,Scratch-B,"table1, vs Li et al",,,,93.78%,,,,,5.4000,,,0.2060,,,,,,,,,,,
31,rethinking-net-pruning,CIFAR-100,DenseNet-40,,"table4, vs slimming",,,,,,,,,,,,,,,,,,,,,,,
36,rethinking-net-pruning,CIFAR-100,DenseNet-BC-100,,"table6, vs han",,,,,,,,,,,,,,,,,,,,,,,
35,rethinking-net-pruning,CIFAR-100,PreResNet-110,,"table6, vs han",,,,,,,,,,,,,,,,,,,,,,,
30,rethinking-net-pruning,CIFAR-100,PreResNet-164,,"table4, vs slimming",,,,,,,,,,,,,,,,,,,,,,,
29,rethinking-net-pruning,CIFAR-100,VGG-19,,"table4, vs slimming",,,,,,,,,,,,,,,,,,,,,,,
23,rethinking-net-pruning,ImageNet,ResNet-34,Scratch-B,"table1, vs Li et al",,,,73.03%,,,,,19.9000,,,3.0800,,,73.31%,,,,,,,,
533,rethinking-net-pruning,ImageNet,ResNet-34,Scratch-B,"table1, vs Li et al",,,,72.91%,,,,,19.3000,,,2.7600,,,,,,,,,,,
25,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table2, vs thinet (scratch-b)",,,,,,-1.010%,,,16.9400,,,4.8800,,,76.13%,,,,,,,,
440,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table2, vs thinet (scratch-b)",,,,,,-2.230%,,,12.3800,,,3.4100,,,76.13%,,,,,,,,
441,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table2, vs thinet (scratch-b)",,,,,,-4.560%,,,8.6600,,,2.2000,,,76.13%,,,,,,,,
536,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table3, vs accel-very-deep",,,,,,-1.070%,,,,,,,,,76.13%,,,,,,2.000,,
537,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table5, vs sss",,,,76.17%,,,,,25.3000,,,3.4730,,,76.12%,,,,,,,,
538,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table5, vs sss",,,,74.67%,,,,,18.6000,,,2.8180,,,76.12%,,,,,,,,
539,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table5, vs sss",,,,73.41%,,,,,15.6000,,,2.3290,,,76.12%,,,,,,,,
586,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table6, vs han",,,,75.70%,,,,,,30.00%,,,,,76.15%,,,,,,,,
587,rethinking-net-pruning,ImageNet,ResNet-50,Scratch-B,"table6, vs han",,,,74.91%,,,,,,60.00%,,,,,76.15%,,,,,,,,
592,rethinking-net-pruning,ImageNet,ResNet-50,Magnitude,"table6, impl of han",,,,76.06%,,,,,,30.00%,,,,,76.15%,,,,,,,,
593,rethinking-net-pruning,ImageNet,ResNet-50,Magnitude,"table6, impl of han",,,,76.09%,,,,,,60.00%,,,,,76.15%,,,,,,,,
24,rethinking-net-pruning,ImageNet,VGG-16,Scratch-B,"table2, vs thinet",,,,,,0.210%,,,131.4400,,,9.5800,,,71.51%,,,,,,,,
535,rethinking-net-pruning,ImageNet,VGG-16,Scratch-B,"table3, vs accel-very-deep",,,,,,-0.510%,,,,,,,,,71.71%,,,,,,5.000,,
588,rethinking-net-pruning,ImageNet,VGG-16,Scratch-B,"table6, vs han",,,,74.02%,,,,,,30.00%,,,,,73.37%,,,,,,,,
589,rethinking-net-pruning,ImageNet,VGG-16,Scratch-B,"table6, vs han",,,,73.42%,,,,,,60.00%,,,,,73.37%,,,,,,,,
590,rethinking-net-pruning,ImageNet,VGG-16,Magnitude,"table6, impl of han",,,,73.68%,,,,,,30.00%,,,,,73.37%,,,,,,,,
591,rethinking-net-pruning,ImageNet,VGG-16,Magnitude,"table6, impl of han",,,,73.63%,,,,,,60.00%,,,,,73.37%,,,,,,,,
32,rethinking-net-pruning,ImageNet,VGG-A+BN-noDrop,,"table4, vs slimming",,,,,,,,,,,,,,,,,,,,,,,
528,rethinking-net-pruning,ImageNet,VGG-GAP,,"table2, vs thinet",,,,,,,,,,,,,,,,,,,,,,,
529,rethinking-net-pruning,ImageNet,VGG-Tiny,,"table2, vs thinet",,,,,,,,,,,,,,,,,,,,,,,
267,rethinking-smaller-norm,CIFAR-10,conv96-192-192-384,,,,,,,,,,,,,,,,,,,,,,,,,
268,rethinking-smaller-norm,ImageNet,ResNet-101,,,,,,,,,,,,,,,,,,,,,,,,,
276,rethinking-smaller-norm,Various Segmentation Datasets,???,,"""We describe an image segmentation experiment whose neural network model is composed from an inception-like network branch and a densenet network branch""",,,,,,,,,,,,,,,,,,,,,,,
265,runtime-neural-pruning,ImageNet,VGG-16,,,,,,,,,,-3.580%,,,,,,,,,,,,,5.000,,
271,runtime-neural-pruning,ImageNet,VGG-16,,,,,,,,,,-2.320%,,,,,,,,,,,,,3.000,,
266,runtime-neural-pruning,ImageNet,VGG-16,,,,,,,,,,-4.890%,,,,,,,,,,,,,10.000,,
272,runtime-neural-pruning,ImageNet,VGG-16,,,,,,,,,,-3.230%,,,,,,,,,,,,,4.000,,
270,runtime-neural-pruning,LFW,conv32-32-64+fc-?-?,,,,,,,,,,,,,,,,,,,,,,,,,
606,samsung-differentiable,CIFAR-10,Plain-20,,table 1,,,,,,,,,,,,,,,,,,,,,,,
605,samsung-differentiable,CIFAR-10,ResNet-56,,table 1,,,,92.70%,,0.040%,,,,,,,,71.00%,92.66%,,,,,,,,
609,samsung-differentiable,CIFAR-10,ResNet-56,,table 1,,,,92.36%,,-0.300%,,,,,,,,52.00%,92.66%,,,,,,,,
604,samsung-differentiable,CIFAR-10,VGG-Torch-CIFAR10,,"table 1; hmm...they compare to pruning-filters, which used the vgg-torch-cifar10 variation, but they only refer to it as VGG-16. So unclear whether it actually is the smaller one or this comparison is not on the same network",,,,,,,,,,,,,,,,,,,,,,,
607,samsung-differentiable,ImageNet,MobileNet,,table 2,,,,68.10%,,-1.460%,,,,,50.00%,,,,69.56%,,,,,,,,
608,samsung-differentiable,ImageNet,VGG-16,,table 2,,,,,,,87.21%,-1.030%,,,,,,,68.38%,,88.24%,,,,,,
611,samsung-differentiable,ImageNet,VGG-16,,table 2,,,,65.12%,,-3.260%,,,,,50.00%,,,,68.38%,,88.24%,,,,,,
246,samsung-vbmf-tucker,ImageNet,???,,"table1; ""four representative CNNs, AlexNet, VGG-S, GoogLeNet, and VGG-16, which can be down- loaded on Berkeley’s Caffe model zoo."" but I definitely can't find a VGG-S (which is what this result is for) on the model zoo... (https://github.com/BVLC/caffe/wiki/Model-Zoo). Though there is ""VGG_CNN_S"" (https://github.com/BVLC/caffe/wiki/Model-Zoo#models-from-the-bmvc-2014-paper-return-of-the-devil-in-the-details-delving-deep-into-convolutional-nets), which is probably what they mean? However, in the original paper (http://www.robots.ox.ac.uk/~vgg/publications/2014/Chatfield14/chatfield14.pdf), the pdf doesn't even include the string ""cifar"", so who knows...",,,,,,,,-0.550%,11.0000,,,0.5490,,,,,,103.000,2.640,,4.800,,
249,samsung-vbmf-tucker,ImageNet,CaffeNet,,"table1; they say alexnet rather than caffenet, but that all their models can be downloaded from caffe model zoo",,,,,,,,-1.700%,,,,0.2720,,,,,,61.000,0.725,,2.670,,
250,samsung-vbmf-tucker,ImageNet,GoogLeNet,,table1,,,,,,,,-0.240%,,,,0.7600,,,,,,6.900,1.566,,2.060,,
248,samsung-vbmf-tucker,ImageNet,VGG-16,,"table1; ""In the case of VGG-16, we only compressed the convolutional layers as done in (Zhang et al., 2015a)""",,,,,,,,-0.500%,,,,3.1390,,,,,,138.000,15.484,,4.930,,
44,samsung-winograd-sparse,ImageNet,AlexNet,,"table2, spatial domain; yes they do say it's 724.4 MACs per image",,,,56.10%,,,79.30%,,,,,0.2400,,,56.80%,,80.00%,,0.724,,,,
447,samsung-winograd-sparse,ImageNet,AlexNet,,"table2, winograd domain",,,,56.00%,,,79.30%,,,,,0.1426,,,56.80%,,80.00%,,0.330,,,,
45,samsung-winograd-sparse,ImageNet,ResNet-18,,"table 2, spatial domain; cites the first resnet paper",,,,67.40%,,,88.20%,,,,,0.8886,,,68.20%,,88.60%,,2.347,,,,
543,samsung-winograd-sparse,ImageNet,ResNet-18,,"table 2, winograd domain; cites the first resnet paper ",,,,67.40%,,,88.20%,,,,,0.5164,,,68.20%,,88.60%,,1.174,,,,
98,smallify,CIFAR-10,VGG-16+Dropout,,,,,,,,,,,,,,,,,,,,,,,,,
99,smallify,Covertype,fc50-50-20,,,,,,,,,,,,,,,,,,,,,,,,,
4,SNIP,CIFAR-10,AlexNet-b,,,,,,,,,,,,,,,,,,,,,,,,,
3,SNIP,CIFAR-10,AlexNet-s,,,,,,,,,,,,,,,,,,,,,,,,,
5,SNIP,CIFAR-10,VGG-C+BN,,,,,,,,,,,,,,,,,,,,,,,,,
6,SNIP,CIFAR-10,VGG-D+BN,,,,,,,,,,,,,,,,,,,,,,,,,
7,SNIP,CIFAR-10,VGG-like,,"""VGG-like (Zagoruyko 2015) is a popular variant adapted for CIFAR-10 which has one less fc layers. For all VGG models, we set the size of the fc layers to 512, remove dropout layers to avoid any effect on sparsification and use batch normalization instead."" But...the zagoruyko model has dropout and batchnorm, not just one less fc layer. And it isn't the same model (for our purposes) if different fc layer sizes",,,,,,,,,,,,,,,,,,,,,,,
8,SNIP,CIFAR-10,WRN-16-8,,,,,,,,,,,,,,,,,,,,,,,,,
9,SNIP,CIFAR-10,WRN-16-10,,,,,,,,,,,,,,,,,,,,,,,,,
10,SNIP,CIFAR-10,WRN-22-8,,,,,,,,,,,,,,,,,,,,,,,,,
2,SNIP,MNIST,LeNet-5,,,,,,,,,,,,,,,,,,,,,,,,,
1,SNIP,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
14,SNIP,Sequential MNIST,GRU-b,,,,,,,,,,,,,,,,,,,,,,,,,
13,SNIP,Sequential MNIST,GRU-s,,,,,,,,,,,,,,,,,,,,,,,,,
12,SNIP,Sequential MNIST,LSTM-b,,,,,,,,,,,,,,,,,,,,,,,,,
11,SNIP,Sequential MNIST,LSTM-s,,,,,,,,,,,,,,,,,,,,,,,,,
16,SNIP,Tiny ImageNet,AlexNet-b,,,,,,,,,,,,,,,,,,,,,,,,,
15,SNIP,Tiny ImageNet,AlexNet-s,,,,,,,,,,,,,,,,,,,,,,,,,
17,SNIP,Tiny ImageNet,VGG-C+BN,,,,,,,,,,,,,,,,,,,,,,,,,
18,SNIP,Tiny ImageNet,VGG-D+BN,,,,,,,,,,,,,,,,,,,,,,,,,
19,SNIP,Tiny ImageNet,VGG-like,,,,,,,,,,,,,,,,,,,,,,,,,
184,soft-filter-pruning,CIFAR-10,ResNet-20,,"PreResNets throughout, it seems",3,,,92.24%,0.33%,,,,,,,0.0344,15.20%,,92.20%,0.18%,,,,,,,
498,soft-filter-pruning,CIFAR-10,ResNet-20,,"for cifar results, ""We run each experiment three times and report the ""mean \pm std""."" (yes they have the inner quotes, and the \pm is mine, not them making a typo)",3,,,91.20%,0.30%,,,,,,,0.0287,29.30%,,92.20%,0.18%,,,,,,,
499,soft-filter-pruning,CIFAR-10,ResNet-20,,,3,,,90.83%,0.31%,,,,,,,0.0243,42.20%,,92.20%,0.18%,,,,,,,
185,soft-filter-pruning,CIFAR-10,ResNet-32,,,3,,,93.22%,0.09%,,,,,,,0.0586,14.90%,,92.63%,0.70%,,,,,,,
500,soft-filter-pruning,CIFAR-10,ResNet-32,,,3,,,90.63%,0.37%,,,,,,,0.0490,28.80%,,92.63%,0.70%,,,,,,,
501,soft-filter-pruning,CIFAR-10,ResNet-32,,,3,,,90.08%,0.08%,,,,,,,0.0403,41.50%,,92.63%,0.70%,,,,,,,
181,soft-filter-pruning,CIFAR-10,ResNet-56,,,3,,,93.89%,0.19%,,,,,,,0.1070,14.70%,,93.59%,0.58%,,,,,,,
502,soft-filter-pruning,CIFAR-10,ResNet-56,,,3,,,92.26%,0.31%,,,,,,,0.0594,52.60%,,93.59%,0.58%,,,,,,,
503,soft-filter-pruning,CIFAR-10,ResNet-56,Fine-Tune,"with ""fine tuning""",3,,,93.35%,0.31%,,,,,,,0.0594,52.60%,,93.59%,0.58%,,,,,,,
504,soft-filter-pruning,CIFAR-10,ResNet-56,,,3,,,93.47%,0.24%,,,,,,,0.0898,28.40%,,93.59%,0.58%,,,,,,,
505,soft-filter-pruning,CIFAR-10,ResNet-56,,,3,,,93.10%,0.20%,,,,,,,0.0740,41.10%,,93.59%,0.58%,,,,,,,
506,soft-filter-pruning,CIFAR-10,ResNet-56,Fine-Tune,"with ""fine tuning""",3,,,93.78%,0.22%,,,,,,,0.0740,41.10%,,93.59%,0.58%,,,,,,,
192,soft-filter-pruning,CIFAR-10,ResNet-110,,,3,,,93.83%,0.19%,,,,,,,0.2160,14.60%,,93.68%,0.32%,,,,,,,
507,soft-filter-pruning,CIFAR-10,ResNet-110,,,3,,,93.93%,0.41%,,,,,,,0.1820,28.20%,,93.68%,0.32%,,,,,,,
508,soft-filter-pruning,CIFAR-10,ResNet-110,Fine-Tune,"with ""fine tuning""",3,,,93.86%,0.21%,,,,,,,0.1500,40.80%,,93.68%,0.32%,,,,,,,
509,soft-filter-pruning,CIFAR-10,ResNet-110,,,3,,,93.38%,0.30%,,,,,,,0.1500,40.80%,,93.68%,0.32%,,,,,,,
193,soft-filter-pruning,ImageNet,ResNet-18,,"not clear what the numbers means; had to infer that ""pruned flops"" and ""Ours(%d\%)"" higher is better based on values in Table 1, which is the one for CIFAR10",,,,67.10%,,,87.78%,,,,,,41.80%,,70.28%,,89.63%,,,,,,
194,soft-filter-pruning,ImageNet,ResNet-34,,,,,,71.83%,,,90.33%,,,,,,41.10%,,73.92%,,91.62%,,,,,,
195,soft-filter-pruning,ImageNet,ResNet-50,,,,,,74.61%,,,92.06%,,,,,,41.80%,,76.15%,,92.87%,,,,,,
510,soft-filter-pruning,ImageNet,ResNet-50,Fine-Tune,"with ""fine-tuning""; I'm deliberately omitting results here because they're so bad they mess up the plots; also seems like authors are arguing that with fine-tuning isn't really their method per se; data that was here:
top1=62.14%
top5=84.60%
saved%=41.80%
origTop1=76.15%
origTop5=92.87%",,,,,,,,,,,,,,,,,,,,,,,
196,soft-filter-pruning,ImageNet,ResNet-101,,,,,,77.03%,,,93.46%,,,,,,42.20%,,77.37%,,93.56%,,,,,,
511,soft-filter-pruning,ImageNet,ResNet-101,,,,,,77.51%,,,93.71%,,,,,,42.20%,,77.37%,,93.56%,,,,,,
216,sparse-evolutionary,Caltech-101-Silhouettes-28x28,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
215,sparse-evolutionary,Caltech101-Silhouettes-16x16,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
221,sparse-evolutionary,CIFAR-10,Family of CNNs,,,,,,,,,,,,,,,,,,,,,,,,,
219,sparse-evolutionary,CIFAR-10,fc4000-1000-4000,,"they say input layer is size 3072, so unclear what they were doing",,,,,,,,,,,,,,,,,,,,,,,
220,sparse-evolutionary,HIGGS,fc1000-1000-1000,,,,,,,,,,,,,,,,,,,,,,,,,
217,sparse-evolutionary,MNIST,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
218,sparse-evolutionary,MNIST,fc1000-1000-1000,,,,,,,,,,,,,,,,,,,,,,,,,
207,sparse-evolutionary,UCI-Adult,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
208,sparse-evolutionary,UCI-Connect4,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
209,sparse-evolutionary,UCI-DNA,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
210,sparse-evolutionary,UCI-Mushrooms,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
211,sparse-evolutionary,UCI-NIPS-0-12,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
212,sparse-evolutionary,UCI-OCR-letters,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
213,sparse-evolutionary,UCI-RCV1,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
214,sparse-evolutionary,UCI-Web,Family of RBMs,,,,,,,,,,,,,,,,,,,,,,,,,
176,sparse-variational-dropout,CIFAR-10,VGG-Torch-CIFAR10,,,,,,,,,,,,,,,,,,,,,,,,,
177,sparse-variational-dropout,CIFAR-100,VGG-Torch-CIFAR10,,,,,,,,,,,,,,,,,,,,,,,,,
179,sparse-variational-dropout,MNIST,LeNet-5-Caffe,,,,,,,,,,,,,,,,,,,,,,,,,
178,sparse-variational-dropout,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
96,spectral-pruning,CIFAR-10,fc300-1000-300,,,,,,,,,,,,,,,,,,,,,,,,,
97,spectral-pruning,ImageNet,VGG-16,Spec-Conv,,,,,71.39%,,,90.63%,,114.6200,,,20.0200,,,68.34%,,88.44%,138.340,30.940,,,,
384,spectral-pruning,ImageNet,VGG-16,Spec-Conv,,,,,72.15%,,,91.06%,,131.4400,,,22.1300,,,68.34%,,88.44%,138.340,30.940,,,,
385,spectral-pruning,ImageNet,VGG-16,Spec-Conv,,,,,71.86%,,,90.88%,,130.3700,,,18.7300,,,68.34%,,88.44%,138.340,30.940,,,,
386,spectral-pruning,ImageNet,VGG-16,Spec-Conv-FC,,,,,68.66%,,,88.90%,,45.7700,,,9.5800,,,68.34%,,88.44%,138.340,30.940,,,,
387,spectral-pruning,ImageNet,VGG-16,Spec-GAP,"""Spec-GAP is a method that replaces the FC layers of Spec-Conv with a global average pooling (GAP) layer""",,,,67.55%,,,88.27%,,8.3100,,,11.2100,,,68.34%,,88.44%,138.340,30.940,,,,
388,spectral-pruning,ImageNet,VGG-16,Spec-Tiny,,,,,60.10%,,,82.89%,,2.3100,,,2.0700,,,68.34%,,88.44%,138.340,30.940,,,,
389,spectral-pruning,ImageNet,VGG-16,Spec-Conv2,,,,,70.09%,,,89.82%,,131.4400,,,9.5800,,,68.34%,,88.44%,138.340,30.940,,,,
390,spectral-pruning,ImageNet,VGG-16,Spec-GAP2,,,,,67.33%,,,87.99%,,8.3200,,,9.3400,,,68.34%,,88.44%,138.340,30.940,,,,
391,spectral-pruning,ImageNet,VGG-16,Spec-GAPe,"""Spec-GAPe sets the parameter $\alpha$ in each layer as $\alpha_l = 0.9944^l$ for the $l$-th layer.""",,,,67.78%,,,88.52%,,8.2500,,,14.7700,,,68.34%,,88.44%,138.340,30.940,,,,
95,spectral-pruning,MNIST,fc300-1000-300,,,,,,,,,,,,,,,,,,,,,,,,,
156,ssl,CIFAR-10,Cifar-net,,"""We implemented the ConvNet of [1]..."" Think this is referring to the ""a particular four-layer convolutional network"" in sec3.2 that isn't described",,,,,,,,,,,,,,,,,,,,,,,
157,ssl,CIFAR-10,ResNet-20,,,,,,,,,,,,,,,,,,,,,,,,,
155,ssl,ImageNet,CaffeNet,,"fig 7a, estimated from measuring px counts",,,,57.85%,,,,,,,,,4.20%,,58.70%,,,,,,,,
482,ssl,ImageNet,CaffeNet,,"fig 7a, estimated from measuring px counts",,,,57.65%,,,,,,,,,17.20%,,58.70%,,,,,,,,
484,ssl,ImageNet,CaffeNet,,"fig 7a, estimated from measuring px counts",,,,56.30%,,,,,,,,,55.80%,,58.70%,,,,,,,,
485,ssl,ImageNet,CaffeNet,,"fig 7a, estimated from measuring px counts",,,,56.00%,,,,,,,,,64.80%,,58.70%,,,,,,,,
486,ssl,ImageNet,CaffeNet,,"fig 7a, estimated from measuring px counts",,,,57.30%,,,,,,,,,38.00%,,58.70%,,,,,,,,
191,ssl,MNIST,fc174-78,,,,,,,,,,,,,,,,,,,,,,,,,
190,ssl,MNIST,fc294-166,,,,,,,,,,,,,,,,,,,,,,,,,
189,ssl,MNIST,fc500-300,,,,,,,,,,,,,,,,,,,,,,,,,
153,ssl,MNIST,fc500-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
154,ssl,MNIST,LeNet-5-Caffe,,"""LeNet [21] implemented by Caffe""",,,,,,,,,,,,,,,,,,,,,,,
77,sss,CIFAR-10,PreResNet-164,,"They call it ResNet-164 but cite the ""Identity Mappings..."" paper",,,,,,,,,,,,,,,,,,,,,,,
76,sss,CIFAR-10,ResNet-20,,"They call it ResNet-20 but cite the ""Identity Mappings..."" paper",,,,,,,,,,,,,,,,,,,,,,,
78,sss,CIFAR-10,ResNext-20,,32 groups/resid block,,,,,,,,,,,,,,,,,,,,,,,
79,sss,CIFAR-10,ResNext-164,,32 groups/resid block,,,,,,,,,,,,,,,,,,,,,,,
75,sss,CIFAR-10,VGG-16+BN-OneFC,,,,,,,,,,,,,,,,,,,,,,,,,
87,sss,ImageNet,PeleeNet,,,,,,,,,,,,,,,,,,,,,,,,,
85,sss,ImageNet,ResNet-50,,"They call it ResNet-50 but cite the ""Identity Mappings..."" paper",,,,75.44%,,,92.61%,,25.3000,,,3.4730,,,76.12%,,92.68%,25.500,4.089,,,,
381,sss,ImageNet,ResNet-50,,"They call it ResNet-50 but cite the ""Identity Mappings..."" paper",,,,74.18%,,,91.91%,,18.6000,,,2.8180,,,76.12%,,92.68%,25.500,4.089,,,,
382,sss,ImageNet,ResNet-50,,"They call it ResNet-50 but cite the ""Identity Mappings..."" paper",,,,71.82%,,,90.79%,,15.6000,,,2.3290,,,76.12%,,92.68%,25.500,4.089,,,,
86,sss,ImageNet,ResNext-50,,,,,,,,,,,,,,,,,,,,,,,,,
380,sss,ImageNet,VGG-16,,,,,,68.53%,,,88.20%,,130.5000,,,7.6670,,,72.46%,,90.84%,138.300,30.970,,,,
336,structured-log-normal,CIFAR-10,VGG-Torch-CIFAR10,,,,,,,,,,,,,,,,,,,,,,,,,
335,structured-log-normal,MNIST,LeNet-5-Caffe,,,,,,,,,,,,,,,,,,,,,,,,,
334,structured-log-normal,MNIST,Lenet-500-300,,"Not actually a ""LeNet"" architecture; they just call it that since it's similar

__NOTE__",,,,,,,,,,,,,,,,,,,,,,,
578,synaptic-strength,CIFAR-10,DenseNet-40,,table1,,,,,,,,,,,,,,,,,,,,,,,
577,synaptic-strength,CIFAR-10,ResNet-18,,table1,,,,,,,,,,,,,,,,,,,,,,,
576,synaptic-strength,CIFAR-10,VGG-netslim,,"table1; they call it ""VGGNet"" but don't specify which; they cite [22] in fig3, which is network-slimming. However, given that net slimming code contradicts paper, unclear what they did",,,,,,,,,,,,,,,,,,,,,,,
579,synaptic-strength,ImageNet,ResNet-50,,table2 (and table3; just same result repeated),,25.32%,7.20%,,,,,,5.9000,,,,,,,,,25.600,,,,24.70%,7.80%
102,sze-energy-aware,ImageNet,AlexNet,,"""We use the models provided by MatConvNet [32] or converted from Caffe [33] or Torch [34]"" matconvnet (http://www.vlfeat.org/matconvnet/pretrained/) gives two pretained alexnets, and just says ""The first model has been imported from Caffe."" And yes, they do actually say it's originally 3.71e8 MACs",,,,,,,79.56%,,5.7300,,,0.0560,,,,,80.43%,60.950,0.371,,,,
103,sze-energy-aware,ImageNet,GoogLeNet,,,,,,,,,,,,,,,,,,,,,,,,,
104,sze-energy-aware,ImageNet,SqueezeNet,,,,,,,,,,,,,,,,,,,,,,,,,
138,thinet-channel-norms,CUB200-2011,AlexNet,,unclear if caffenet; transfer learning experiment,,,,,,,,,,,,,,,,,,,,,,,
137,thinet-channel-norms,CUB200-2011,VGG-16,,transfer learning experiment,,,,,,,,,,,,,,,,,,,,,,,
134,thinet-channel-norms,CUB200-2011,VGG-16-AvgPool,,"runs 4x and reports avg, though not any measure of variation",4,,,,,,,,,,,,,,,,,,,,,,
136,thinet-channel-norms,ImageNet,ResNet-50,,,,,,72.04%,,,90.67%,,16.9400,,,4.8800,,,72.88%,,91.14%,25.560,7.720,,,,
438,thinet-channel-norms,ImageNet,ResNet-50,,,,,,71.01%,,,90.02%,,12.3800,,,3.4100,,,72.88%,,91.14%,25.560,7.720,,,,
439,thinet-channel-norms,ImageNet,ResNet-50,,,,,,68.42%,,,88.30%,,8.6600,,,2.2000,,,72.88%,,91.14%,25.560,7.720,,,,
135,thinet-channel-norms,ImageNet,VGG-16,,"They call this one Thinet-Conv.
-""For a fair comparison, the accuracy of original VGG-16 model is evaluated on resized center-cropped images using pre-trained model as adopted in [10, 14]. The same strategy is also used in ResNet-50.""",,,,69.80%,,,89.53%,,131.4400,,,9.5800,,,68.34%,,88.44%,138.340,30.940,,,,
397,thinet-channel-norms,ImageNet,VGG-GAP,,,,,,,,,,,,,,,,,,,,,,,,,
530,thinet-channel-norms,ImageNet,VGG-Tiny,,,,,,,,,,,,,,,,,,,,,,,,,
140,thinet-channel-norms,Indoor-67-balanced,AlexNet,,unclear if caffenet; transfer learning experiment,,,,,,,,,,,,,,,,,,,,,,,
139,thinet-channel-norms,Indoor-67-balanced,VGG-16,,transfer learning experiment,,,,,,,,,,,,,,,,,,,,,,,
594,uiuc-coreset-pruning,CUB200-2011,VGG-16,AP+Coreset-S,table 6,,,,,,,,,,,,,,,,,,,,,,,
371,uiuc-coreset-pruning,ImageNet,AlexNet,AP+Coreset-K,"table1, AP+Coreset-K",,,,56.51%,,,,,4.0200,,,,,,57.22%,,,61.000,,,,,
545,uiuc-coreset-pruning,ImageNet,AlexNet,AP+Coreset-S,"table1, AP+Coreset-S",,,,56.38%,,,,,3.2000,,,,,,57.22%,,,61.000,,,,,
546,uiuc-coreset-pruning,ImageNet,AlexNet,AP+Coreset-A,"table1, AP+Coreset-A",,,,56.48%,,,,,3.6800,,,,,,57.22%,,,61.000,,,,,
567,uiuc-coreset-pruning,ImageNet,ResNet-18,AP+Coreset-K,"table3, AP+Coreset-K; only 2 sigfigs...",,,,69.00%,,,,,,,,,,,69.00%,,,,,13.30,,,
570,uiuc-coreset-pruning,ImageNet,ResNet-18,AP+Coreset-S,"table3, AP+Coreset-S; only 2 sigfigs...",,,,68.00%,,,,,,,,,,,69.00%,,,,,15.00,,,
571,uiuc-coreset-pruning,ImageNet,ResNet-18,AP+Coreset-A,"table3, AP+Coreset-A; only 2 sigfigs...",,,,69.00%,,,,,,,,,,,69.00%,,,,,14.20,,,
568,uiuc-coreset-pruning,ImageNet,ResNet-50,AP+Coreset-K,"table3, AP+Coreset-K; only 2 sigfigs...",,,,74.00%,,,,,,,,,,,75.00%,,,,,14.70,,,
572,uiuc-coreset-pruning,ImageNet,ResNet-50,AP+Coreset-S,"table3, AP+Coreset-S; only 2 sigfigs...",,,,74.00%,,,,,,,,,,,75.00%,,,,,15.80,,,
573,uiuc-coreset-pruning,ImageNet,ResNet-50,AP+Coreset-A,"table3, AP+Coreset-A; only 2 sigfigs...",,,,74.00%,,,,,,,,,,,75.00%,,,,,15.60,,,
569,uiuc-coreset-pruning,ImageNet,ResNet-101,AP+Coreset-K,"table3, AP+Coreset-K; only 2 sigfigs...",,,,75.00%,,,,,,,,,,,76.00%,,,,,15.10,,,
574,uiuc-coreset-pruning,ImageNet,ResNet-101,AP+Coreset-S,"table3, AP+Coreset-S; only 2 sigfigs...",,,,75.00%,,,,,,,,,,,76.00%,,,,,16.20,,,
575,uiuc-coreset-pruning,ImageNet,ResNet-101,AP+Coreset-A,"table3, AP+Coreset-A; only 2 sigfigs...",,,,75.00%,,,,,,,,,,,76.00%,,,,,15.80,,,
551,uiuc-coreset-pruning,ImageNet,SqueezeNet,AP+Coreset-K,"table1, AP+Coreset-K",,,,56.52%,,,,,0.6500,,,,,,57.01%,,,1.240,,,,,
552,uiuc-coreset-pruning,ImageNet,SqueezeNet,AP+Coreset-S,"table1, AP+Coreset-S",,,,56.44%,,,,,0.5900,,,,,,57.01%,,,1.240,,,,,
553,uiuc-coreset-pruning,ImageNet,SqueezeNet,AP+Coreset-A,"table1, AP+Coreset-A",,,,56.80%,,,,,0.6000,,,,,,57.01%,,,1.240,,,,,
544,uiuc-coreset-pruning,ImageNet,VGG-16,AP+Coreset-K,"table1, AP+Coreset-K",,,,68.56%,,,,,9.8100,,,,,,68.88%,,,138.000,,,,,
548,uiuc-coreset-pruning,ImageNet,VGG-16,AP+Coreset-S,"table1, AP+Coreset-S",,,,67.90%,,,,,8.1000,,,,,,68.88%,,,138.000,,,,,
549,uiuc-coreset-pruning,ImageNet,VGG-16,AP+Coreset-A,"table1, AP+Coreset-A",,,,68.16%,,,,,8.7000,,,,,,68.88%,,,138.000,,,,,
550,uiuc-coreset-pruning,MNIST,LeNet-5,,"table 5, only reports layerwise compression, with no mention of accuracy, and only gives compression to 1 significant figure...",,,,,,,,,,,,,,,,,,,,,,,
595,uiuc-coreset-pruning,Stanford-Dogs,VGG-16,AP+Coreset-S,table 6,,,,,,,,,,,,,,,,,,,,,,,
255,welling-slow-quantize+prune,CIFAR-10,WRN-16-4,,,,,,,,,,,,,,,,,,,,,,,,,
259,welling-slow-quantize+prune,CIFAR-100,WRN-16-4,,,,,,,,,,,,,,,,,,,,,,,,,
247,welling-slow-quantize+prune,MNIST,LeNet-5-Caffe,,,,,,,,,,,,,,,,,,,,,,,,,
254,welling-slow-quantize+prune,MNIST,LeNet-300-100,,,,,,,,,,,,,,,,,,,,,,,,,
282,zhang-accel-very-deep,ImageNet,AlexNet,,"""The comparison is based on our re-implementation of AlexNet."" Also, ""Our re-implementation of this model has top-5 single- view error rate as 18.8% (10-view top-5 16.0% and top- 1 37.6%). This is better than the one reported in [4].""
-Also, can't find alexnet numbers in here, except for each layer",,,,,,,,,,,,,,,62.40%,,81.20%,,,,,,
280,zhang-accel-very-deep,ImageNet,SPP-10,,,,,,,,,,,,,,,,,,,,,,,,,
281,zhang-accel-very-deep,ImageNet,VGG-16,,"table 7, ""our asym. (3d) FT"" 3x",,,,,,,,0.000%,,,,,,,,,10.10%,,,,3.000,,
582,zhang-accel-very-deep,ImageNet,VGG-16,,"table 7, ""our asym. (3d) FT"" 4x",,,,,,,,-0.300%,,,,,,,,,10.10%,,,,4.000,,
583,zhang-accel-very-deep,ImageNet,VGG-16,,"table 7, ""our asym. (3d) FT"" 5x",,,,,,,,-1.000%,,,,,,,,,10.10%,,,,5.000,,
283,zhang-accel-very-deep,Pascal VOC 2007,VGG-16,,using Faster R-CNN,,,,,,,,,,,,,,,,,,,,,,,
361,zhuang-discriminative-channel,CIFAR-10,???,,"They call it ""VGGNet"" without specifying which VGG network (and since running on CIFAR, likely to be some weird variation. They cite  [31] for it, which is (O. M. Parkhi, A. Vedaldi, A. Zisserman, et al. Deep face recognition. In BMVC, volume 1, page 6, 2015.) but this describes 3 networks, which are slight variations of VGG A, B, and D from the original VGG paper that they use for face recognition",,,,,,,,,,,,,,,,,,,,,,,
363,zhuang-discriminative-channel,CIFAR-10,MobileNet,,,,,,,,,,,,,,,,,,,,,,,,,
364,zhuang-discriminative-channel,CIFAR-10,MobileNet-v2,,,,,,,,,,,,,,,,,,,,,,,,,
362,zhuang-discriminative-channel,CIFAR-10,ResNet-56,,"table 1, dcp",,,,,,-0.310%,,,,,,,,,93.80%,,,,,1.97,1.990,,
522,zhuang-discriminative-channel,CIFAR-10,ResNet-56,,"table 1, dcp-adapt",,,,,,0.010%,,,,,,,,,93.80%,,,,,3.37,1.890,,
372,zhuang-discriminative-channel,ImageNet,ResNet-18,,table 5,,30.79%,11.14%,,,,,,,30.00%,,,,,69.64%,,88.98%,,,,,,
523,zhuang-discriminative-channel,ImageNet,ResNet-18,,table 5,,32.65%,12.40%,,,,,,,50.00%,,,,,69.64%,,88.98%,,,,,,
524,zhuang-discriminative-channel,ImageNet,ResNet-18,,table 5,,35.88%,14.32%,,,,,,,70.00%,,,,,69.64%,,88.98%,,,,,,
365,zhuang-discriminative-channel,ImageNet,ResNet-50,,table 5,,23.60%,6.93%,,,-1.060%,,-0.610%,,30.00%,,,,,76.01%,,92.93%,,,,,,
525,zhuang-discriminative-channel,ImageNet,ResNet-50,,table 5,,27.25%,8.87%,,,-1.060%,,-0.610%,,70.00%,,,,,76.01%,,92.93%,,,,,,
526,zhuang-discriminative-channel,ImageNet,ResNet-50,,"table 3, dcp (no dcp-adapt results reported?)",,,,,,-1.060%,,-0.610%,,,,,,,,,,,,2.06,2.250,,
527,zhuang-discriminative-channel,ImageNet,ResNet-50,,table 5,,25.05%,7.68%,,,-1.060%,,-0.610%,,50.00%,,,,,76.01%,,92.93%,,,,,,
369,zhuang-discriminative-channel,LFW,???,,"same VGGNet comment as above; ie:  They call it ""VGGNet"" without specifying which VGG network (and since running on CIFAR, likely to be some weird variation. They cite  [31] for it, which is (O. M. Parkhi, A. Vedaldi, A. Zisserman, et al. Deep face recognition. In BMVC, volume 1, page 6, 2015.) but this describes 3 networks, which are slight variations of VGG A, B, and D from the original VGG paper that they use for face recognition",,,,,,,,,,,,,,,,,,,,,,,
368,zhuang-discriminative-channel,LFW,DeepFace,,,,,,,,,,,,,,,,,,,,,,,,,
367,zhuang-discriminative-channel,LFW,FaceNet,,"""We use CASIA-WebFace...for training""",,,,,,,,,,,,,,,,,,,,,,,
370,zhuang-discriminative-channel,LFW,SphereNet-4,,,,,,,,,,,,,,,,,,,,,,,,,